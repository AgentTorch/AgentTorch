{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78eceb51-f267-432c-b701-c26ee895ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import agent-torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../AgentTorch'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from AgentTorch import Runner, Registry\n",
    "from AgentTorch.substep import SubstepObservation, SubstepAction, SubstepTransition\n",
    "from AgentTorch.helpers import get_by_path, read_config, read_from_file, grid_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9bf334-53ea-4661-ace5-f13dc6df61f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import all external libraries that we need.\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "717974c9-7f6c-4f79-adf2-7be4d17e60e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define the helper functions we need.\n",
    "\n",
    "def get_var(state, var):\n",
    "  \"\"\"\n",
    "    Retrieves a value from the current state of the model.\n",
    "  \"\"\"\n",
    "  return get_by_path(state, re.split('/', var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e21f43-7677-41c8-9fda-0919b0e65e0f",
   "metadata": {},
   "source": [
    "# Predator-Prey Model\n",
    "\n",
    "> The complete code for this model can be found [here](../). The architecture of\n",
    "> the AgentTorch framework, which explains some key concepts, can be found\n",
    "> [here](https://github.com/AgentTorch/AgentTorch/pull/9/files?short_path=140eef3#diff-140eef3ba41bdcf401d507408084181f2c0ac627532b61e0f7906ea7cc926782).\n",
    "\n",
    "This guide walks you through creating a custom predator-prey model using the\n",
    "AgentTorch framework. This model will simulate an ecosystem consisting of\n",
    "predators, prey and grass: predators eat prey, and prey eat grass.\n",
    "\n",
    "The model's parameters, rules and configuration are passed to AgentTorch, which\n",
    "iteratively simulates the model, allowing you to optimize its learnable\n",
    "parameters, while also modelling the simulation in real time. AgentTorch's\n",
    "Python API is based on PyTorch, which enhances its performance on GPUs.\n",
    "\n",
    "The following sections detail:\n",
    "\n",
    "- an overview of the model's rules and parameters.\n",
    "- the properties of all entities stored in the model's state.\n",
    "- the substeps that observe, simulate and modify the state for each agent.\n",
    "- the code required to run the simulation using `agent-torch`.\n",
    "- plotting the state's trajectory using `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d1423-cc33-4d21-9820-d0bfa1671044",
   "metadata": {},
   "source": [
    "## Model Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55bf57-e458-42a7-8970-5d3937387df7",
   "metadata": {},
   "source": [
    "The following are configurable parameters of the model:\n",
    "\n",
    "- a $n \\times m$ grid, with $p$ predators and $q$ prey to start with.\n",
    "- grass can grown on any of the $n \\cdot m$ squares in the grid.\n",
    "\n",
    "The rules followed by the simulated interactions are configured as follows:\n",
    "\n",
    "- predators can eat only prey, and prey can eat only grass.\n",
    "- grass grows back once eaten after a certain number of steps.\n",
    "- upon consuming food, the energy of the consumer increases.\n",
    "- movement happens randomly, to any neighbouring square in the grid.\n",
    "- each move reduces the energy of the entity by a fixed amount.\n",
    "\n",
    "These parameters and rules, along with the properties of the entities (detailed\n",
    "below) in the simulation are defined in a configuration file, and passed on to\n",
    "the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084035b-5643-4783-9d3f-189ba93f2158",
   "metadata": {},
   "source": [
    "## State: Environment, Agents, and Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33143a7e-205f-4419-bdc2-3ab05b145279",
   "metadata": {},
   "source": [
    "The model's state consists of a list of properties of the simulated environment,\n",
    "and the agents and objects situated in that simulation. For this model, the:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73b05b-5928-4ca4-8f82-193d4499e9a0",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "The environment will have only one property: the size of the two-dimensional\n",
    "grid in which the predators and prey wander, defined like so:\n",
    "\n",
    "```yaml\n",
    "environment:\n",
    "  bounds: (max_x, max_y) # tuple of integers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331b58c-30d8-4445-84c9-70ce7d29842e",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    "This model has two agents: predator, and prey.\n",
    "\n",
    "#### Predator\n",
    "\n",
    "The predator agent is defined like so:\n",
    "\n",
    "```yaml\n",
    "predator:\n",
    "  coordinates: (x, y) # tuple of integers\n",
    "  energy: float\n",
    "  stride_work: float\n",
    "```\n",
    "\n",
    "The `coordinates` property depicts the current position of the predator in the\n",
    "two-dimensional grid. It is initialized from a CSV file that contains a list of\n",
    "randomly generated coordinates for all 40 predators.\n",
    "\n",
    "The `energy` property stores the current amount of energy possessed by the\n",
    "predator. Initially, this property is set to a random number between 30 and 100.\n",
    "\n",
    "The `stride_work` property is a static, but learnable property that stores the\n",
    "amount of energy to deduct from a predator for one step in any direction on the\n",
    "grid.\n",
    "\n",
    "#### Prey\n",
    "\n",
    "The prey agent is identical to the predator agent, and has one additional\n",
    "property: `nutritional_value`.\n",
    "\n",
    "```yaml\n",
    "prey:\n",
    "  coordinates: (x, y) # tuple of integers\n",
    "  energy: float\n",
    "  stride_work: float\n",
    "  nutritional_value: float\n",
    "```\n",
    "\n",
    "The `nutritional_value` property is a static but learnable property that stores\n",
    "the amount of energy gained by a predator when it consumes a single prey entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcdd982-630f-4aaa-b1b4-ab9fa0063a7a",
   "metadata": {},
   "source": [
    "### Objects\n",
    "\n",
    "This model has only one agent: grass.\n",
    "\n",
    "#### Grass\n",
    "\n",
    "The grass entity is defined as follows:\n",
    "\n",
    "```yaml\n",
    "grass:\n",
    "  coordinates: (x, y)\n",
    "  growth_stage: 0|1\n",
    "  growth_countdown: float\n",
    "  regrowth_time: float\n",
    "  nutritional_value: float\n",
    "```\n",
    "\n",
    "The `coordinates` property depicts the current position of the predator in the\n",
    "two-dimensional grid. It is initialized from a CSV file that contains a list of\n",
    "all 1600 coordinates.\n",
    "\n",
    "The `growth_stage` property stores the current growth stage of the grass: 0\n",
    "means it is growing, and 1 means it is fully grown.\n",
    "\n",
    "The `growth_countdown` property stores the number of steps after which the grass\n",
    "becomes fully grown. The `regrowth_time` property is static and learnable, and\n",
    "stores the max value of the countdown property.\n",
    "\n",
    "The `nutritional_value` property is a static but learnable property that stores\n",
    "the amount of energy gained by a predator when it consumes a single prey entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d685d69-0e42-43ef-9c1d-e0f65f926dcf",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a1192-4952-4fc0-a40b-3e0cbf449c93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The model makes use of the adjacency matrix of a two-dimensional grid filled\n",
    "with predator and prey to simulate the movement of those entities.\n",
    "\n",
    "```yaml\n",
    "network:\n",
    "  agent_agent:\n",
    "    grid: [predator, prey]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f253b-5ffe-45c1-9d09-72beadf42ec2",
   "metadata": {},
   "source": [
    "## Substeps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1af2c-9a47-40ac-9651-df4bfb87680f",
   "metadata": {},
   "source": [
    "Each substep is a `torch.nn.ModuleDict` that takes an input state, and produces\n",
    "an updated state as output. A substep consists of three phases:\n",
    "\n",
    "1. Observation (retrieving relevant information from the state)\n",
    "2. Policy/Action (deciding on the course of action as per the observations)\n",
    "3. Transition (randomizing and updating the state according to the action)\n",
    "\n",
    "This model consists of four substeps: `move`, `eat_grass`, `hunt_prey`, and\n",
    "`grow_grass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c36c5895-de21-4de2-b3c6-b2ac1d1d6bbb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define all the helper functions we need.\n",
    "\n",
    "def get_neighbors(pos, adj_grid, bounds):\n",
    "  \"\"\"\n",
    "    Returns a list of neighbours for each position passed in the given\n",
    "    `pos` tensor, using the adjacency matrix passed in `adj_grid`.\n",
    "  \"\"\"\n",
    "  x, y = pos\n",
    "  max_x, max_y = bounds\n",
    "\n",
    "  # calculate the node number from the x, y coordinate.\n",
    "  # each item (i, j) in the adjacency matrix, if 1 depicts\n",
    "  # that i is connected to j and vice versa.\n",
    "  node = (max_y * x) + y\n",
    "  conn = adj_grid[node]\n",
    "\n",
    "  neighbors = []\n",
    "  for idx, cell in enumerate(conn):\n",
    "    # if connected, calculate the (x, y) coords of the other\n",
    "    # node and add it to the list of neighbors.\n",
    "    if cell == 1:\n",
    "      c = (int) (idx % max_y)\n",
    "      r = math.floor((idx - c) / max_y)\n",
    "\n",
    "      neighbors.append(\n",
    "        [torch.tensor(r), torch.tensor(c)]\n",
    "      )\n",
    "\n",
    "  return torch.tensor(neighbors)\n",
    "\n",
    "# define a function to retrieve the input required\n",
    "def get_find_neighbors_input(state, input_variables):\n",
    "    bounds = get_var(state, input_variables['bounds'])\n",
    "    adj_grid = get_var(state, input_variables['adj_grid'])\n",
    "    positions = get_var(state, input_variables['positions'])\n",
    "    \n",
    "    return bounds, adj_grid, positions\n",
    "\n",
    "def get_decide_movement_input(state, input_variables):\n",
    "    positions = get_var(state, input_variables['positions'])\n",
    "    energy = get_var(state, input_variables['energy'])\n",
    "    \n",
    "    return positions, energy\n",
    "\n",
    "def get_update_positions_input(state, input_variables):\n",
    "    prey_energy = get_var(state, input_variables['prey_energy'])\n",
    "    pred_energy = get_var(state, input_variables['pred_energy'])\n",
    "    prey_work = get_var(state, input_variables['prey_work'])\n",
    "    pred_work = get_var(state, input_variables['pred_work'])\n",
    "\n",
    "    return prey_energy, pred_energy, prey_work, pred_work\n",
    "\n",
    "def get_find_eatable_grass_input(state, input_variables):\n",
    "    bounds = get_var(state, input_variables['bounds'])\n",
    "    positions = get_var(state, input_variables['positions'])\n",
    "    grass_growth = get_var(state, input_variables['grass_growth'])\n",
    "\n",
    "    return bounds, positions, grass_growth\n",
    "\n",
    "def get_eat_grass_input(state, input_variables):\n",
    "    bounds = get_var(state, input_variables['bounds'])\n",
    "    prey_pos = get_var(state, input_variables['prey_pos'])\n",
    "    energy = get_var(state, input_variables['energy'])\n",
    "    nutrition = get_var(state, input_variables['nutrition'])\n",
    "    grass_growth = get_var(state, input_variables['grass_growth'])\n",
    "    growth_countdown = get_var(state, input_variables['growth_countdown'])\n",
    "    regrowth_time = get_var(state, input_variables['regrowth_time'])\n",
    "\n",
    "    return bounds, prey_pos, energy, nutrition, grass_growth, growth_countdown, regrowth_time\n",
    "\n",
    "def get_find_targets_input(state, input_variables):\n",
    "    prey_pos = get_var(state, input_variables['prey_pos'])\n",
    "    pred_pos = get_var(state, input_variables['pred_pos'])\n",
    "\n",
    "    return prey_pos, pred_pos\n",
    "\n",
    "def get_hunt_prey_input(state, input_variables):\n",
    "    prey_pos = get_var(state, input_variables['prey_pos'])\n",
    "    prey_energy = get_var(state, input_variables['prey_energy'])\n",
    "    pred_pos = get_var(state, input_variables['pred_pos'])\n",
    "    pred_energy = get_var(state, input_variables['pred_energy'])\n",
    "    nutrition = get_var(state, input_variables['nutritional_value'])\n",
    "\n",
    "    return prey_pos, prey_energy, pred_pos, pred_energy, nutrition\n",
    "\n",
    "def get_grow_grass_input(state, input_variables):\n",
    "    grass_growth = get_var(state, input_variables['grass_growth'])\n",
    "    growth_countdown = get_var(state, input_variables['growth_countdown'])\n",
    "\n",
    "    return grass_growth, growth_countdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b3491-2e79-4eec-b0c5-0e2861626d46",
   "metadata": {},
   "source": [
    "### Move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810ce5e-ff96-4c40-a3ec-a4665e1f64a4",
   "metadata": {},
   "source": [
    "First, we **observe** the state, and find a list of neighboring positions for\n",
    "each of the predators/prey currently alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d69b7f9-614a-4390-b1e6-563b1e8259fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"find_neighbors\", \"observation\")\n",
    "class FindNeighbors(SubstepObservation):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state):\n",
    "    bounds, adj_grid, positions = get_find_neighbors_input(state, self.input_variables)\n",
    "\n",
    "    # for each agent (prey/predator), find the adjacent cells and pass\n",
    "    # them on to the policy class.\n",
    "    possible_neighbors = []\n",
    "    for pos in positions:\n",
    "      possible_neighbors.append(\n",
    "        get_neighbors(pos, adj_grid, bounds)\n",
    "      )\n",
    "\n",
    "    return { self.output_variables[0]: possible_neighbors }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be27d44-6fc1-4049-b61d-9069d114f73f",
   "metadata": {},
   "source": [
    "Then, we decide the course of **action**: to move each entity to a random\n",
    "neighboring position, only if they have the energy to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34cf0999-fdfc-45d3-8fba-898d49186e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"decide_movement\", \"policy\")\n",
    "class DecideMovement(SubstepAction):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, observations):\n",
    "    positions, energy = get_decide_movement_input(state, self.input_variables)\n",
    "    possible_neighbors = observations['possible_neighbors']\n",
    "\n",
    "    # randomly choose the next position of the agent. if the agent\n",
    "    # has non-positive energy, don't let it move.\n",
    "    next_positions = []\n",
    "    for idx, pos in enumerate(positions):\n",
    "      next_positions.append(\n",
    "        random.choice(possible_neighbors[idx]) if energy[idx] > 0 else pos\n",
    "      )\n",
    "\n",
    "    return { self.output_variables[0]: torch.stack(next_positions, dim=0) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612413d6-7a9e-414b-b6e7-d8ba1fc969b3",
   "metadata": {},
   "source": [
    "Lastly, we **update** the state, with the new positions of the entities, and\n",
    "reduce the energy of each entity by the value of the `stride_work` learnable\n",
    "parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47bcef28-5a17-4ae3-9300-07aeae5fe386",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"update_positions\", \"transition\")\n",
    "class UpdatePositions(SubstepTransition):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, action):\n",
    "    prey_energy, pred_energy, prey_work, pred_work = get_update_positions_input(state, self.input_variables)\n",
    "\n",
    "    # reduce the energy of the agent by the work required by them\n",
    "    # to take one step.\n",
    "    prey_energy = prey_energy + torch.full(prey_energy.shape, -1 * (prey_work.item()))\n",
    "    pred_energy = pred_energy + torch.full(pred_energy.shape, -1 * (pred_work.item()))\n",
    "    \n",
    "    return {\n",
    "      self.output_variables[0]: action['prey']['next_positions'],\n",
    "      self.output_variables[1]: prey_energy,\n",
    "      self.output_variables[2]: action['predator']['next_positions'],\n",
    "      self.output_variables[3]: pred_energy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611f84e-ef8a-42cf-b8ba-3e33377c0236",
   "metadata": {},
   "source": [
    "### Eat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66012cb9-aff8-4706-bc3b-86bcd8d9cc46",
   "metadata": {},
   "source": [
    "First, **decide** which grass is fit to be consumed by the prey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3e7a03-194f-4aae-a062-e7951cd22b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"find_eatable_grass\", \"policy\")\n",
    "class FindEatableGrass(SubstepAction):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, observations):\n",
    "    bounds, positions, grass_growth = get_find_eatable_grass_input(state, self.input_variables)\n",
    "\n",
    "    # if the grass is fully grown, i.e., its growth_stage is equal to\n",
    "    # 1, then it can be consumed by prey.\n",
    "    eatable_grass_positions = []\n",
    "    max_x, max_y = bounds\n",
    "    for pos in positions:\n",
    "      x, y = pos\n",
    "      node = (max_y * x) + y\n",
    "      if grass_growth[node] == 1:\n",
    "        eatable_grass_positions.append(pos)\n",
    "\n",
    "    # pass on the consumable grass positions to the transition class.\n",
    "    return { self.output_variables[0]: eatable_grass_positions }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca3c1a-6a89-42ea-93f9-8ccd94e8c3b7",
   "metadata": {},
   "source": [
    "Then, simulate the consumption of the grass, and **update** the growth stage,\n",
    "growth countdown, and energies of the grass and prey respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e484125a-2172-4a34-b10e-c76532f9f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"eat_grass\", \"transition\")\n",
    "class EatGrass(SubstepTransition):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, action):\n",
    "    bounds, prey_pos, energy, nutrition, grass_growth, growth_countdown, regrowth_time = get_eat_grass_input(state, self.input_variables)\n",
    "\n",
    "    # if no grass can be eaten, skip modifying the state.\n",
    "    if len(action['prey']['eatable_grass_positions']) < 1:\n",
    "      return {}\n",
    "\n",
    "    eatable_grass_positions = torch.stack(action['prey']['eatable_grass_positions'], dim=0)\n",
    "    max_x, max_y = bounds\n",
    "    energy_mask = None\n",
    "    grass_mask, countdown_mask = torch.zeros(*grass_growth.shape), torch.zeros(*growth_countdown.shape)\n",
    "\n",
    "    # for each consumable grass, figure out if any prey agent is at\n",
    "    # that position. if yes, then mark that position in the mask as\n",
    "    # true. also, for all the grass that will be consumed, reset the\n",
    "    # growth stage.\n",
    "    for pos in eatable_grass_positions:\n",
    "      x, y = pos\n",
    "      node = (max_y * x) + y\n",
    "\n",
    "      # TODO: make sure dead prey cannot eat\n",
    "      e_m = (pos == prey_pos).all(dim=1).view(-1, 1)\n",
    "      if energy_mask is None:\n",
    "        energy_mask = e_m\n",
    "      else:\n",
    "        energy_mask = e_m + energy_mask\n",
    "\n",
    "      grass_mask[node] = -1\n",
    "      countdown_mask[node] = regrowth_time - growth_countdown[node]\n",
    "\n",
    "    # energy + nutrition adds the `nutrition` tensor to all elements in\n",
    "    # the energy tensor. the (~energy_mask) ensures that the change is\n",
    "    # undone for those prey that did not consume grass.\n",
    "    energy = energy_mask*(energy + nutrition) + (~energy_mask)*energy\n",
    "\n",
    "    # these masks use simple addition to make changes to the original\n",
    "    # values of the tensors.\n",
    "    grass_growth = grass_growth + grass_mask\n",
    "    growth_countdown = growth_countdown + countdown_mask\n",
    "\n",
    "    return {\n",
    "      self.output_variables[0]: energy,\n",
    "      self.output_variables[1]: grass_growth,\n",
    "      self.output_variables[2]: growth_countdown\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad5b01-eb77-4cf0-9ea6-f33144fe385e",
   "metadata": {},
   "source": [
    "### Hunt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4e0b4-23c6-4b3e-8752-c392697c0c4c",
   "metadata": {},
   "source": [
    "First, **decide** which prey are to be eaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe70afbb-577d-4525-9061-7bce26a95914",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"find_targets\", \"policy\")\n",
    "class FindTargets(SubstepAction):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, observations):\n",
    "    prey_pos, pred_pos = get_find_targets_input(state, self.input_variables)\n",
    "\n",
    "    # if there are any prey at the same position as a predator,\n",
    "    # add them to the list of targets to kill.\n",
    "    target_positions = []\n",
    "    for pos in pred_pos:\n",
    "      if (pos == prey_pos).all(-1).any(-1) == True:\n",
    "        target_positions.append(pos)\n",
    "\n",
    "    # pass that list of targets to the transition class.\n",
    "    return { self.output_variables[0]: target_positions }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73ce0b-ff42-4c08-8c38-2ea524d71a7b",
   "metadata": {},
   "source": [
    "Then, **update** the energies of both the prey and the predator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9975011-7c99-4837-b88b-224efe6ff80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"hunt_prey\", \"transition\")\n",
    "class HuntPrey(SubstepTransition):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, action):\n",
    "    prey_pos, prey_energy, pred_pos, pred_energy, nutrition = get_hunt_prey_input(state, self.input_variables)\n",
    "\n",
    "    # if there are no targets, skip the state modifications.\n",
    "    if len(action['predator']['target_positions']) < 1:\n",
    "      return {}\n",
    "\n",
    "    target_positions = torch.stack(action['predator']['target_positions'], dim=0)\n",
    "\n",
    "    # these are masks similars to the ones in `substeps/eat.py`.\n",
    "    prey_energy_mask = None\n",
    "    pred_energy_mask = None\n",
    "    for pos in target_positions:\n",
    "      pye_m = (pos == prey_pos).all(dim=1).view(-1, 1)\n",
    "      if prey_energy_mask is None:\n",
    "        prey_energy_mask = pye_m\n",
    "      else:\n",
    "        prey_energy_mask = prey_energy_mask + pye_m\n",
    "\n",
    "      pde_m = (pos == pred_pos).all(dim=1).view(-1, 1)\n",
    "      if pred_energy_mask is None:\n",
    "        pred_energy_mask = pde_m\n",
    "      else:\n",
    "        pred_energy_mask = pred_energy_mask + pde_m\n",
    "\n",
    "    # any prey that is marked for death should be given zero energy.\n",
    "    prey_energy = prey_energy_mask*0 + (~prey_energy_mask)*prey_energy\n",
    "    # any predator that has hunted should be given additional energy.\n",
    "    pred_energy = pred_energy_mask*(pred_energy + nutrition) + (~pred_energy_mask)*pred_energy\n",
    "\n",
    "    return {\n",
    "      self.output_variables[0]: prey_energy,\n",
    "      self.output_variables[1]: pred_energy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff06ffe-4e1c-4d30-a82d-46096951e52a",
   "metadata": {},
   "source": [
    "### Grow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bfb5ef-b801-4a8f-96cb-cb0482e78a04",
   "metadata": {},
   "source": [
    "In this substep, we simply **update** the growth countdown of every grass\n",
    "object, and if the countdown has elapsed, we update the growth stage to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1551a25-a8be-4c88-8be3-750aa66f268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Registry.register_substep(\"grow_grass\", \"transition\")\n",
    "class GrowGrass(SubstepTransition):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def forward(self, state, action):\n",
    "    grass_growth, growth_countdown = get_grow_grass_input(state, self.input_variables)\n",
    "\n",
    "    # reduce all countdowns by 1 unit of time.\n",
    "    growth_countdown_mask = torch.full(growth_countdown.shape, -1)\n",
    "    growth_countdown = growth_countdown + growth_countdown_mask\n",
    "\n",
    "    # if the countdown has reached zero, set the growth stage to 1,\n",
    "    # otherwise, keep it zero.\n",
    "    grass_growth_mask = (growth_countdown <= 0).all(dim=1)\n",
    "    grass_growth = grass_growth_mask*(1) + (~grass_growth_mask)*(0)\n",
    "\n",
    "    return {\n",
    "      self.output_variables[0]: grass_growth.view(-1, 1),\n",
    "      self.output_variables[1]: growth_countdown\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f5c87-48a1-49a4-a40a-551053343471",
   "metadata": {},
   "source": [
    "## Execution: Configuration, Registry, and Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2888d-c5d6-4660-ae54-570de6fae76f",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "There are several parts to the configuration, written in a file traditionally\n",
    "called `config.yaml`. The following is a brief overview of all the major\n",
    "sections in the configuration file.\n",
    "\n",
    "```yaml\n",
    "# config.yaml\n",
    "# configuration for the predator-prey model.\n",
    "\n",
    "metadata:\n",
    "  # device type, episode count, data files, etc.\n",
    "\n",
    "state:\n",
    "  environment:\n",
    "    # variables/properties of the simulated enviroment.\n",
    "\n",
    "  agents:\n",
    "    # a list of agents in the simulation, and their properties.\n",
    "    # each property must be initialized by specifying a value\n",
    "    # or a generator function, and have a fixed tensor shape.\n",
    "\n",
    "  objects:\n",
    "    # a list of objects, similar to the agents list.\n",
    "\n",
    "  network:\n",
    "    # a list of interaction models for the simulation.\n",
    "    # could be a grid, or a directed graph, etc.\n",
    "\n",
    "substeps:\n",
    "  # a list of substeps\n",
    "  # each substep has a list of agents to run that substep for\n",
    "  # as well as the function, input and output variables for each\n",
    "  # part of that substep (observation, policy and transition)\n",
    "```\n",
    "\n",
    "The following is an example of defining a property in the configuration.\n",
    "\n",
    "```yaml\n",
    "bounds:\n",
    "  name: 'Bounds'\n",
    "  learnable: false\n",
    "  shape: 2\n",
    "  dtype: 'int'\n",
    "  value:\n",
    "    - ${simulation_metadata.max_x} # you can refer to other parts of the config using\n",
    "    - ${simulation_metadata.max_y} # the template syntax, i.e., ${path.to.config.value}\n",
    "  initialization_function: null\n",
    "```\n",
    "\n",
    "Notice that to define one single property, we mentioned:\n",
    "\n",
    "- the name of the property, here, `'bounds'`.\n",
    "- whether or not the property is learnable, in this case, `false`.\n",
    "- the shape of the tensor that stores the values, in this case, it is a\n",
    "  one-dimensional array of two elements: `(max_x, max_y)`.\n",
    "- the value of the property, either by directly providing the value or by\n",
    "  providing a function that returns the value.\n",
    "\n",
    "The full configuration for the predator-prey model can be found\n",
    "[here](../config.yaml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "435beca9-a540-471c-9df4-a7b199c2548a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define helper functions used in the configuration\n",
    "\n",
    "@Registry.register_helper('map', 'network')\n",
    "def map_network(params):\n",
    "  coordinates = (40.78264403323726, -73.96559413265355) # central park\n",
    "  distance = 550\n",
    "\n",
    "  graph = ox.graph_from_point(coordinates, dist=distance, simplify=True, network_type=\"walk\")\n",
    "  adjacency_matrix = nx.adjacency_matrix(graph).todense()\n",
    "\n",
    "  return graph, torch.tensor(adjacency_matrix)\n",
    "\n",
    "@Registry.register_helper('random_float', 'initialization')\n",
    "def random_float(shape, params):\n",
    "  \"\"\"\n",
    "    Generates a `Tensor` of the given shape, with random floating point\n",
    "    numbers in between and including the lower and upper limit.\n",
    "  \"\"\"\n",
    "\n",
    "  max = params['upper_limit'] + 1 # include max itself.\n",
    "  min = params['lower_limit']\n",
    "\n",
    "  # torch.rand returns a tensor of the given shape, filled with\n",
    "  # floating point numbers in the range (0, 1]. multiplying the\n",
    "  # tensor by max - min and adding the min value ensure it's\n",
    "  # within the given range.\n",
    "  tens = (max - min) * torch.rand(shape) + min\n",
    "\n",
    "  return tens\n",
    "\n",
    "@Registry.register_helper('random_int', 'initialization')\n",
    "def random_int(shape, params):\n",
    "  \"\"\"\n",
    "    Generates a `Tensor` of the given shape, with random integers in\n",
    "    between and including the lower and upper limit.\n",
    "  \"\"\"\n",
    "\n",
    "  max = math.floor(params['upper_limit'] + 1) # include max itself.\n",
    "  min = math.floor(params['lower_limit'])\n",
    "\n",
    "  # torch.randint returns the tensor we need.\n",
    "  tens = torch.randint(min, max, shape)\n",
    "\n",
    "  return tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a3b10-7265-404e-8a48-c0ba1f4298b9",
   "metadata": {},
   "source": [
    "### Registry and Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174fbe67-2be6-4a41-8244-7fd1338dfc99",
   "metadata": {},
   "source": [
    "The code that **executes** the simulation uses the AgentTorch `Registry` and `Runner`, like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcf733f-8378-422e-a2e1-996eb4c4b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config('config-map.yaml')\n",
    "metadata = config.get('simulation_metadata')\n",
    "num_episodes = metadata.get('num_episodes')\n",
    "num_steps_per_episode = metadata.get('num_steps_per_episode')\n",
    "num_substeps_per_step = metadata.get('num_substeps_per_step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b566c-18d1-405f-9a96-72c8442c557a",
   "metadata": {},
   "source": [
    "The registry is stores all the classes and functions used by the model, and\n",
    "allows the runner to call them as needed when intializing the simulation and\n",
    "executing the substeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd21a63-409d-4fb7-b9df-aead821da8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = Registry()\n",
    "registry.register(read_from_file, 'read_from_file', 'initialization')\n",
    "registry.register(grid_network, 'grid', key='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e0361f-50b5-4a85-8980-50db49eddc88",
   "metadata": {},
   "source": [
    "The runner intializes and executes the simulation for us. It also returns:\n",
    "\n",
    "- a list of the learnable parameters, so we can run optimization functions on\n",
    "  them and use the optimized values for the next episode.\n",
    "- the trajectory of the state so far, so we can visualize the state using\n",
    "  libraries like `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d0d4084-3707-42bc-9a45-0332fbd314f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(config, registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a78148-afb3-4d24-be3f-30b250b42d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.init()\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "  runner.step(num_steps_per_episode)\n",
    "  \n",
    "  final_states = list(filter(\n",
    "    lambda x: x['current_substep'] == str(num_substeps_per_step - 1),\n",
    "    runner.state_trajectory[-1]\n",
    "  ))\n",
    "  visualizer = Plot(metadata.get('max_x'), metadata.get('max_y'))\n",
    "  visualizer.plot(final_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc629569-dd4d-4da6-b8fe-f405dcec39ba",
   "metadata": {},
   "source": [
    "In the next section, we'll write a visualizer that plots the entities'\n",
    "populations on a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8486c-c7b7-4ab6-b0ba-a0eb4d40fad9",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f356c5a-8901-4fa3-9ec7-0d62d1d6125e",
   "metadata": {},
   "source": [
    "You can plot the simulation in different ways. In this notebook, two such methods are demonstrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f472d8d-c731-4036-8b87-2bda02f12a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <video alt=\"test\" controls>\n",
       "        <source src=\"https://raw.githubusercontent.com/AgentTorch/AgentTorch/master/models/predatorprey/predator-prey.mp4\" type=\"video/mp4\">\n",
       "    </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the grid gif\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "    <video alt=\"test\" controls>\n",
    "        <source src=\"https://raw.githubusercontent.com/AgentTorch/AgentTorch/master/models/predatorprey/predator-prey.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae354821-4234-4c67-9b60-01593b59e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plotter\n",
    "import matplotlib.patches as patcher\n",
    "import contextily as ctx\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class Plot:\n",
    "  def __init__(self, max_x, max_y):\n",
    "    # intialize the scatterplot\n",
    "    self.figure, self.axes = None, None\n",
    "    self.prey_scatter, self.pred_scatter = None, None\n",
    "    self.max_x, self.max_y = max_x, max_y\n",
    "\n",
    "    plotter.xlim(0, max_x - 1)\n",
    "    plotter.ylim(0, max_y - 1)\n",
    "    self.i = 0\n",
    "\n",
    "  def update(self, state):\n",
    "    graph = state['network']['agent_agent']['predator_prey']['graph']\n",
    "    self.coords = [(node[1]['x'], node[1]['y']) for node in graph.nodes(data=True)]\n",
    "    self.coords.sort(key=lambda x: -(x[0] + x[1]))\n",
    "\n",
    "    self.figure, self.axes = ox.plot_graph(graph, edge_linewidth=0.3, edge_color='gray', show=False, close=False)\n",
    "    ctx.add_basemap(self.axes, crs=graph.graph['crs'], source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "    self.axes.set_axis_off()\n",
    "\n",
    "    # get coordinates of all the entities to show.\n",
    "    prey = state['agents']['prey']\n",
    "    pred = state['agents']['predator']\n",
    "    grass = state['objects']['grass']\n",
    "\n",
    "    # agar energy > 0 hai... toh zinda ho tum!\n",
    "    alive_prey = prey['coordinates'][torch.where(prey['energy'] > 0)[0]]\n",
    "    alive_pred = pred['coordinates'][torch.where(pred['energy'] > 0)[0]]\n",
    "    # show only fully grown grass, which can be eaten.\n",
    "    grown_grass = grass['coordinates'][torch.where(grass['growth_stage'] == 1)[0]]\n",
    "\n",
    "    alive_prey_x, alive_prey_y = np.array([\n",
    "      self.coords[(self.max_y * pos[0]) + pos[1]] for pos in alive_prey\n",
    "    ]).T\n",
    "    alive_pred_x, alive_pred_y = np.array([\n",
    "      self.coords[(self.max_y * pos[0]) + pos[1]] for pos in alive_pred\n",
    "    ]).T\n",
    "\n",
    "    # show prey in dark blue and predators in maroon.\n",
    "    self.axes.scatter(alive_prey_x, alive_prey_y, c='#0d52bd', marker='.')\n",
    "    self.axes.scatter(alive_pred_x, alive_pred_y, c='#8b0000', marker='.')\n",
    "\n",
    "    # increment the step count.\n",
    "    self.i += 1\n",
    "    # show the current step count, and the population counts.\n",
    "    self.axes.set_title('Predator-Prey Simulation #' + str(self.i), loc='left')\n",
    "    self.axes.legend(handles=[\n",
    "      patcher.Patch(color='#fc46aa', label=str(self.i) + ' step'),\n",
    "      patcher.Patch(color='#0d52bd', label=str(len(alive_prey)) + ' prey'),\n",
    "      patcher.Patch(color='#8b0000', label=str(len(alive_pred)) + ' predators'),\n",
    "      # patcher.Patch(color='#d1ffbd', label=str(len(grown_grass)) + ' grass')\n",
    "    ])\n",
    "    \n",
    "    display(plotter.gcf())\n",
    "    clear_output(wait=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "  def plot(self, states):\n",
    "    # plot each state, one-by-one\n",
    "    for state in states:\n",
    "      self.update(state)\n",
    "\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b912b-564a-405d-b082-9d90349f7920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
