{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "057359a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import json\n",
    "\n",
    "AGENT_TORCH_PATH = '/u/ayushc/projects/GradABM/MacroEcon/AgentTorch'\n",
    "MODEL_PATH = '/u/ayushc/projects/GradABM/MacroEcon/models'\n",
    "sys.path.append(MODEL_PATH)\n",
    "sys.path.insert(0, AGENT_TORCH_PATH)\n",
    "\n",
    "from AgentTorch.LLM.llm_agent import LLMAgent\n",
    "from AgentTorch.substep import SubstepAction\n",
    "from AgentTorch.helpers import get_by_path\n",
    "from macro_economics.prompt import prompt_template_var,agent_profile\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef001615",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7956858",
   "metadata": {},
   "source": [
    "## Data Required for LLM Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78595914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'30t39', '65A', '40t49', 'U19', '50t64', '20t29'}\n",
      "{'Male', 'Female'}\n"
     ]
    }
   ],
   "source": [
    "age_values = set([ix['age'] for ix in combinations_of_prompt_variables])\n",
    "gender_values = set([ix['gender'] for ix in combinations_of_prompt_variables])\n",
    "\n",
    "age_map = {'U19': 0, '20t29': 1, '30t39': 2, '40t49': 3, '50t64': 4, '65A': 5}\n",
    "gender_map = {'Male': 0, 'Female': 1}\n",
    "\n",
    "print(age_values)\n",
    "print(gender_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8118adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_of_prompt_variables_with_index = [{'gender': 0, 'age': 0}, {'gender': 0, 'age': 1}, {'gender': 0, 'age': 2}, {'gender': 0, 'age': 3}, {'gender': 0, 'age': 4}, {'gender': 0, 'age': 5}, {'gender': 1, 'age': 0}, {'gender': 1, 'age': 1}, {'gender': 1, 'age': 2}, {'gender': 1, 'age': 3}, {'gender': 1, 'age': 4}, {'gender': 1, 'age': 5}]\n",
    "\n",
    "combinations_of_prompt_variables = [{'gender': 'Male', 'age': 'U19'}, {'gender': 'Male', 'age': '20t29'}, {'gender': 'Male', 'age': '30t39'}, {'gender': 'Male', 'age': '40t49'}, {'gender': 'Male', 'age': '50t64'}, {'gender': 'Male', 'age': '65A'}, {'gender': 'Female', 'age': 'U19'}, {'gender': 'Female', 'age': '20t29'}, {'gender': 'Female', 'age': '30t39'}, {'gender': 'Female', 'age': '40t49'}, {'gender': 'Female', 'age': '50t64'}, {'gender': 'Female', 'age': '65A'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7cf29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_age = np.load('../../debug_age.npy')\n",
    "agent_gender = np.load('../../debug_gender.npy')\n",
    "consumption_propensity = np.load('../../debug_consumption_propensity.npy')\n",
    "work_propensity = np.load('../../debug_work_propensity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6fb957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent = LLMAgent(agent_profile = agent_profile,openai_api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec3d3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_gender = torch.from_numpy(agent_gender)\n",
    "agents_age = torch.from_numpy(agent_age)\n",
    "consumption_propensity = torch.from_numpy(consumption_propensity)\n",
    "work_propensity = torch.from_numpy(work_propensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229f96d",
   "metadata": {},
   "source": [
    "## Forward Execution Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf4b511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "output_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "759c66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_values in combinations_of_prompt_variables_with_index:\n",
    "    gender_mask = (agents_gender == target_values['gender'])\n",
    "    age_mask = (agents_age == target_values['age'])\n",
    "    mask = torch.logical_and(gender_mask, age_mask).unsqueeze(1) # ayush fix -> to ensure consistent adding later\n",
    "    float_mask = mask.float()\n",
    "    masks.append(float_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "185acbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for en,_ in enumerate(combinations_of_prompt_variables_with_index):\n",
    "    age = combinations_of_prompt_variables[en]['age']\n",
    "    gender = combinations_of_prompt_variables[en]['gender']\n",
    "    prompt = prompt_template_var.format(age = age,gender = gender)\n",
    "    output_value = llm_agent(prompt)\n",
    "    output_values.append(output_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ef98622",
   "metadata": {},
   "outputs": [],
   "source": [
    "for en,output_value in enumerate(output_values):\n",
    "    output_value = json.loads(output_value)\n",
    "    group_work_propensity = output_value['work']\n",
    "    group_consumption_propensity = output_value['consumption']\n",
    "    consumption_propensity_for_group = masks[en]*group_consumption_propensity\n",
    "    consumption_propensity = torch.add(consumption_propensity,consumption_propensity_for_group)\n",
    "    work_propensity_for_group = masks[en]*group_work_propensity\n",
    "    work_propensity = torch.add(work_propensity,work_propensity_for_group)\n",
    "\n",
    "# work_propensity = torch.rand(16573530,1)\n",
    "whether_to_work = torch.bernoulli(work_propensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "58720211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_keys_values(dictionary):\n",
    "    return {v: k for k, v in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0de5eb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'U19', 1: '20t29', 2: '30t39', 3: '40t49', 4: '50t64', 5: '65A'},\n",
       " {0: 'Male', 1: 'Female'})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_age_map = swap_keys_values(age_map)\n",
    "index_gender_map = swap_keys_values(gender_map)\n",
    "\n",
    "index_age_map, index_gender_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc95174",
   "metadata": {},
   "source": [
    "## torch.vmap code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "132c0feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['30t39', '30t39', '65A', '65A', '40t49', '40t49', 'U19', 'U19', '50t64', '50t64', '20t29', '20t29'] ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "vmap(llm_agent_wrapper, in_dims=0, ...)(<inputs>): Got in_dim=0 for an input but the input is of type <class 'str'>. We cannot vmap over non-Tensor arguments, please use None as the respective in_dim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ages = torch.tensor([combo['age'] for combo in combinations_of_prompt_variables]).unsqueeze(1)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# genders = torch.tensor([combo['gender'] for combo in combinations_of_prompt_variables]).unsqueeze(1)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(ages, genders)\n\u001b[0;32m---> 35\u001b[0m work_propensities, consumption_propensities \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_agent_wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m consumption_propensity \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m*\u001b[39m consumption_propensities, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m work_propensity \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(masks \u001b[38;5;241m*\u001b[39m work_propensities, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/agent_torch_env/lib/python3.8/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/agent_torch_env/lib/python3.8/site-packages/torch/_functorch/vmap.py:270\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m lazy_load_decompositions()\n\u001b[1;32m    269\u001b[0m _check_out_dims_is_int_or_int_pytree(out_dims, func)\n\u001b[0;32m--> 270\u001b[0m batch_size, flat_in_dims, flat_args, args_spec \u001b[38;5;241m=\u001b[39m \u001b[43m_process_batched_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     chunks_flat_args \u001b[38;5;241m=\u001b[39m _get_chunked_inputs(flat_args, flat_in_dims, batch_size, chunk_size)\n",
      "File \u001b[0;32m~/agent_torch_env/lib/python3.8/site-packages/torch/_functorch/vmap.py:110\u001b[0m, in \u001b[0;36m_process_batched_inputs\u001b[0;34m(in_dims, args, func)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmap(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_name(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in_dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ...)(<inputs>): \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot in_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for an input but in_dim must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124man integer dimension or None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(in_dim, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Tensor):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmap(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_name(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in_dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ...)(<inputs>): \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot in_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for an input but the input is of type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. We cannot vmap over non-Tensor arguments, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use None as the respective in_dim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (in_dim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39marg\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mor\u001b[39;00m in_dim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mdim()):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmap(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_name(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in_dims=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ...)(<inputs>): \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot in_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for some input, but that input is a Tensor \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mof dimensionality \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m so expected in_dim to satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <= in_dim < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: vmap(llm_agent_wrapper, in_dims=0, ...)(<inputs>): Got in_dim=0 for an input but the input is of type <class 'str'>. We cannot vmap over non-Tensor arguments, please use None as the respective in_dim"
     ]
    }
   ],
   "source": [
    "def llm_agent_wrapper(age, gender):\n",
    "    prompt = prompt_template_var.format(age=index_age_map[age], gender=index_gender_map[gender])\n",
    "    output_value = llm_agent(prompt)\n",
    "    output_value = json.loads(output_value)\n",
    "    group_work_propensity = output_value['work']\n",
    "    group_consumption_propensity = output_value['consumption']\n",
    "    return group_work_propensity, group_consumption_propensity\n",
    "\n",
    "combinations_of_prompt_variables = [{'age': age, 'gender': gender} for age in age_values for gender in gender_values]\n",
    "\n",
    "age_masks = []\n",
    "gender_masks = []\n",
    "for target_values in combinations_of_prompt_variables:\n",
    "    age_mask = (agents_age == age_mapping[target_values['age']]).unsqueeze(1)\n",
    "    gender_mask = (agents_gender == gender_mapping[target_values['gender']]).unsqueeze(1)\n",
    "    mask = torch.logical_and(age_mask, gender_mask).float()\n",
    "    age_masks.append(age_mask)\n",
    "    gender_masks.append(gender_mask)\n",
    "\n",
    "age_masks = torch.cat(age_masks, dim=1)\n",
    "gender_masks = torch.cat(gender_masks, dim=1)\n",
    "masks = torch.logical_and(age_masks, gender_masks) # (num_agents, num_combinations)\n",
    "\n",
    "ages = [combo['age'] for combo in combinations_of_prompt_variables]\n",
    "genders = [combo['gender'] for combo in combinations_of_prompt_variables]\n",
    "\n",
    "# ages = torch.tensor([combo['age'] for combo in combinations_of_prompt_variables]).unsqueeze(1)\n",
    "# genders = torch.tensor([combo['gender'] for combo in combinations_of_prompt_variables]).unsqueeze(1)\n",
    "\n",
    "print(ages, genders)\n",
    "\n",
    "work_propensities, consumption_propensities = torch.vmap(llm_agent_wrapper)(ages, genders)\n",
    "\n",
    "consumption_propensity = torch.sum(masks * consumption_propensities, dim=1)\n",
    "work_propensity = torch.sum(masks * work_propensities, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4a0d8",
   "metadata": {},
   "source": [
    "## Clean Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f841ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_agent_wrapper(age, gender):\n",
    "    prompt = prompt_template_var.format(age=index_age_map[age], gender=index_gender_map[gender])\n",
    "    output_value = llm_agent(prompt)\n",
    "    output_value = json.loads(output_value)\n",
    "    group_work_propensity = output_value['work']\n",
    "    group_consumption_propensity = output_value['consumption']\n",
    "    return group_work_propensity, group_consumption_propensity\n",
    "\n",
    "combinations_of_prompt_variables = [{'age': age, 'gender': gender} for age in age_values for gender in gender_values]\n",
    "\n",
    "age_masks = []\n",
    "gender_masks = []\n",
    "for target_values in combinations_of_prompt_variables:\n",
    "    age_mask = (agents_age == age_mapping[target_values['age']]).unsqueeze(1)\n",
    "    gender_mask = (agents_gender == gender_mapping[target_values['gender']]).unsqueeze(1)\n",
    "    mask = torch.logical_and(age_mask, gender_mask).float()\n",
    "    age_masks.append(age_mask)\n",
    "    gender_masks.append(gender_mask)\n",
    "\n",
    "age_masks = torch.cat(age_masks, dim=1)\n",
    "gender_masks = torch.cat(gender_masks, dim=1)\n",
    "masks = torch.logical_and(age_masks, gender_masks)\n",
    "\n",
    "work_propensities = []\n",
    "consumption_propensities = []\n",
    "for combo in combinations_of_prompt_variables:\n",
    "    age = age_map[combo['age']]\n",
    "    gender = gender_map[combo['gender']]\n",
    "    work_prop, cons_prop = llm_agent_wrapper(age, gender)\n",
    "    work_propensities.append(work_prop)\n",
    "    consumption_propensities.append(cons_prop)\n",
    "\n",
    "work_propensities = torch.tensor(work_propensities)\n",
    "consumption_propensities = torch.tensor(consumption_propensities)\n",
    "\n",
    "consumption_propensity = torch.sum(masks * consumption_propensities, dim=1)\n",
    "work_propensity = torch.sum(masks * work_propensities, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2d687cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37518])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption_propensity.shape\n",
    "work_propensity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fae2ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    a1 = a + 2\n",
    "    b1 = b + 4\n",
    "    \n",
    "    return a1*b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c4e3782d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18., 32., 50.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([2, 4, 6])\n",
    "\n",
    "torch.vmap(my_func)(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9c9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
