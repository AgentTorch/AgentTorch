{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _income_to_pua(agent_incomes):\n",
    "    threshold = 304.0*torch.ones_like(agent_incomes)\n",
    "    pua_amount = torch.min(agent_incomes / 2, threshold)\n",
    "\n",
    "    return pua_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eligible_pua_payments(payment_amount, shape, request_date, delay=28, frequency=7, num_payments=26):\n",
    "    agent_pua_payments = payment_amount*torch.zeros_like(shape)\n",
    "\n",
    "    start_date = request_date + delay\n",
    "    end_date = request_date + frequency*num_payments\n",
    "\n",
    "    first_amount = payment_amount*(delay // frequency)\n",
    "    recurring_amount = payment_amount\n",
    "\n",
    "    return start_date, end_date, first_amount, recurring_amount\n",
    "\n",
    "    agent_pua_payments[start_date] = first_amount\n",
    "    agent_pua_payments[start_date + frequency: end_date: frequency] = recurring_amount\n",
    "\n",
    "    return agent_pua_payments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 0\n",
    "\n",
    "start_date_tensor = torch.zeros(())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each stimulus, we have to do the following:\n",
    "1. Initialize eligibility\n",
    "2. Update eligibility\n",
    "3. If eligible, define payment_amount, payment_frequency, payment_delay\n",
    "\n",
    "- StimulusPayment\n",
    "    - Eligibility defined once at start of the simulation\n",
    "    - Fixed amount for all, one-time payments: Initialized at the start of the simulation\n",
    "- FPEC\n",
    "    - Eligiblity defined implicitly for all unemployed people\n",
    "        - At each step, [eligible_agents = (occupation_status == unemployed)]\n",
    "    - Fixed amount for all, weekly payments, fixed interval program\n",
    "- PUA\n",
    "    - Eligibilty defined on individual request.\n",
    "        - Initialize simulation with some eligible agents. [eligible = unemployed*request_pua_assistance]\n",
    "        - During simulation, policy for agents to request assistance.\n",
    "            - Action: Sample agent eligibility, weekly amount, start date.\n",
    "    - Variable amount for all, calculated once when eligibility defined.\n",
    "\n",
    "Tensors to store:\n",
    "1. Agent_Eligiblity\n",
    "2. Agent_Stimulus_Amount - (num_agents,)\n",
    "3. Agent_Stimulus_Dates - (num_steps,)\n",
    "\n",
    "4. Agent_Stimulus_Payment - (Payment is in-frequent and same for all) - (num_steps,) and sparse_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Works with torch.sparse_tensor and torch.vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs...\n",
      "agent payments:  torch.Size([2]) tensor([100., 304.])\n",
      "num steps:  torch.Size([23])\n",
      "-------------\n",
      "BatchedTensor(lvl=1, bdim=0, value=\n",
      "    tensor([100., 304.])\n",
      ") BatchedTensor(lvl=1, bdim=0, value=\n",
      "    tensor([100., 304.])\n",
      ")\n",
      "batched pua payments:  tensor([[  0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         100.,   0.,   0.,   0.,   0.,   0.,   0., 100.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0., 304.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "         304.,   0.,   0.,   0.,   0.,   0.,   0., 304.,   0.,   0.,   0.]])\n",
      "pua payments tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "---------------\n",
      "tensor(indices=tensor([[ 0,  0,  0,  2,  2,  2],\n",
      "                       [ 5, 12, 19,  5, 12, 19]]),\n",
      "       values=tensor([100., 100., 100., 304., 304., 304.]),\n",
      "       size=(4, 23), nnz=6, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# pua_payments tensor\n",
    "import math\n",
    "\n",
    "def _income_to_pua(agent_incomes):\n",
    "    threshold = 304.0*torch.ones_like(agent_incomes)\n",
    "    pua_amount = torch.min(agent_incomes / 2, threshold)\n",
    "\n",
    "    return pua_amount\n",
    "\n",
    "# write for one agent\n",
    "def get_pua_payments(payment_amount, shape, request_date, delay=3, frequency=7, num_payments=26):\n",
    "    agent_pua_payments = payment_amount*torch.zeros_like(shape)\n",
    "\n",
    "    start_date = request_date + delay\n",
    "    end_date = request_date + frequency*num_payments\n",
    "    first_amount = payment_amount*math.ceil(delay / frequency)\n",
    "    recurring_amount = payment_amount\n",
    "\n",
    "    print(first_amount, recurring_amount)\n",
    "\n",
    "    agent_pua_payments[start_date] = first_amount\n",
    "    agent_pua_payments[start_date + frequency: end_date: frequency] = recurring_amount\n",
    "\n",
    "    return agent_pua_payments\n",
    "\n",
    "num_agents = 4\n",
    "num_steps = 23\n",
    "request_date = 2\n",
    "agents_income = torch.tensor([200, 800], dtype=torch.float32)\n",
    "num_steps_shape = torch.ones((num_steps))\n",
    "\n",
    "pua_payments = torch.zeros((num_agents, num_steps))\n",
    "sparse_pua_payments = pua_payments.to_sparse_coo()\n",
    "\n",
    "requesting_agents_indices = torch.tensor([0, 2])\n",
    "requesting_agents_incomes = torch.tensor([200, 800], dtype=torch.float32)\n",
    "requesting_payment_amount = _income_to_pua(requesting_agents_incomes)\n",
    "\n",
    "print(\"Inputs...\")\n",
    "print(\"agent payments: \", requesting_payment_amount.shape, requesting_payment_amount)\n",
    "print(\"num steps: \", num_steps_shape.shape)\n",
    "print(\"-------------\")\n",
    "\n",
    "batched_pua_payments_func = torch.vmap(get_pua_payments, in_dims=(0, None, None))\n",
    "batched_pua_payments = batched_pua_payments_func(requesting_payment_amount, num_steps_shape, request_date)\n",
    "sparse_batched_pua_payments = batched_pua_payments.to_sparse_coo()\n",
    "\n",
    "chunked_batched_pua = batched_pua_payments.chunk(chunks=num_agents, dim=0)\n",
    "chunked_pua_payments = pua_payments.chunk(chunks=num_agents, dim=0)\n",
    "\n",
    "print(\"batched pua payments: \", batched_pua_payments)\n",
    "print(\"pua payments\", pua_payments)\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "pua_payments[requesting_agents_indices] = batched_pua_payments\n",
    "sparse_pua_payments = pua_payments.to_sparse_coo()\n",
    "\n",
    "print(sparse_pua_payments)\n",
    "# sparse_batched_pua_payments = batched_pua_payments.to_sparse_coo()\n",
    "# print(batched_pua_payments.shape, sparse_batched_pua_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000],\n",
      "        [ 0.2881, -0.4046,  0.0959]])\n",
      "--------------------\n",
      "torch.Size([1, 3])\n",
      "tensor([[  0.0000,   0.0000,   0.0000],\n",
      "        [101.0000, 101.0000, 101.0000],\n",
      "        [100.2881,  99.5954, 100.0959]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.zeros((1, 3))\n",
    "x2 = torch.ones((1, 3))\n",
    "x3 = torch.randn((1, 3))\n",
    "\n",
    "x = torch.vstack([x1, x2, x3])\n",
    "\n",
    "update_indices = [1, 2]\n",
    "updated_x = x[update_indices] + 100\n",
    "print(updated_x.shape)\n",
    "\n",
    "print(x)\n",
    "print(\"--------------------\")\n",
    "\n",
    "x_chunk = x.chunk(chunks=3, dim=0)\n",
    "print(x_chunk[0].shape)\n",
    "\n",
    "x[update_indices] = updated_x\n",
    "\n",
    "print(x)\n",
    "\n",
    "3 // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "input:  torch.Size([4]) tensor([-0.8818,  1.4248, -0.4376,  0.2385])\n",
      "torch.Size([5]) tensor([1., 1., 1., 1., 1.])\n",
      "-------------\n",
      "output:  torch.Size([4, 5]) tensor([[-0.0000, 27.1182, -2.8818, -0.0000, -0.0000],\n",
      "        [ 0.0000, 29.4248, -0.5752,  0.0000,  0.0000],\n",
      "        [-0.0000, 27.5624, -2.4376, -0.0000, -0.0000],\n",
      "        [ 0.0000, 28.2385, -1.7615,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "## debugging torch.vmap design\n",
    "\n",
    "def _from_x(x):\n",
    "    return x\n",
    "\n",
    "def func(x, s):\n",
    "    # val = _from_x(x)\n",
    "    # print(val, val.shape)\n",
    "    ret_val = x*torch.zeros_like(s)\n",
    "    ret_val[1] = x*5\n",
    "\n",
    "    ret_val[2: 8: 3] = x - 1\n",
    "\n",
    "    return ret_val\n",
    "\n",
    "def func2(agent_payments, num_steps, delay=28, frequency=2):\n",
    "    agent_pua = agent_payments*torch.zeros_like(num_steps)\n",
    "\n",
    "    agent_pua[1] = agent_payments + delay\n",
    "    agent_pua[2: 20: 4] = agent_payments - 2\n",
    "\n",
    "    return agent_pua\n",
    "\n",
    "agent_payments = torch.randn((4)) # (num_agents)\n",
    "num_steps = torch.ones((5)) # (num_steps)\n",
    "\n",
    "batched_pow = torch.vmap(func2, in_dims=(0, None))\n",
    "\n",
    "print(\"-------------\")\n",
    "print(\"input: \", agent_payments.shape, agent_payments)\n",
    "print(num_steps.shape, num_steps)\n",
    "print(\"-------------\")\n",
    "\n",
    "ans = batched_pow(agent_payments, num_steps)\n",
    "\n",
    "print(\"output: \", ans.shape, ans)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start PUA for agents during a specific simulation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pua_payments tensor\n",
    "def _income_to_pua(agent_incomes):\n",
    "    threshold = 304.0*torch.ones_like(agent_incomes)\n",
    "    pua_amount = torch.min(agent_incomes / 2, threshold)\n",
    "\n",
    "    return pua_amount\n",
    "\n",
    "def get_at_indices(tensor, indices):\n",
    "    return tensor[indices]\n",
    "\n",
    "# write for one agent\n",
    "def get_pua_payments(payment_amount, shape, request_date, delay=3, frequency=7, num_payments=26):\n",
    "    '''Computes PUA for a single agent'''\n",
    "    agent_pua_payments = payment_amount*torch.zeros_like(shape)\n",
    "\n",
    "    start_date = request_date + delay\n",
    "    end_date = request_date + frequency*num_payments\n",
    "    first_amount = payment_amount*math.ceil(delay / frequency)\n",
    "    recurring_amount = payment_amount\n",
    "\n",
    "    agent_pua_payments[start_date] = first_amount\n",
    "    agent_pua_payments[start_date + frequency: end_date: frequency] = recurring_amount\n",
    "\n",
    "    return agent_pua_payments\n",
    "\n",
    "def start_pua(t, pua_payments, agents_enrollment_status, requesting_pua_agents, agents_income, agents_employment):\n",
    "    eligible_agents = (agents_employment == 0) # unemployed agents are eligible\n",
    "    payment_amounts = _income_to_pua(agents_income)\n",
    "\n",
    "    newly_enrolled_agents = eligible_agents*requesting_pua_agents*(1 - agents_enrollment_status) # all requesting eligible agents receive it if they don't actively do yet\n",
    "    newly_enrolled_agents_indices = torch.gather(newly_enrolled_agents, dim=1) # gather their indices\n",
    "\n",
    "    batched_pua_payments_func = torch.vmap(get_pua_payments, in_dims=(0, None, None))\n",
    "    batched_pua_payments = batched_pua_payments_func(requesting_payment_amount, num_steps_shape, request_date)\n",
    "\n",
    "    pua_payments[newly_enrolled_agents_indices] = batched_pua_payments\n",
    "    pua_payments = pua_payments.to_sparse_coo()\n",
    "\n",
    "    # update enrollment status\n",
    "    agents_enrollment_status = agents_enrollment_status*(1 - newly_enrolled_agents) + newly_enrolled_agents*(1 - agents_enrollment_status)\n",
    "\n",
    "    return pua_payments, agents_enrollment_status\n",
    "\n",
    "\n",
    "pua_payments = torch.zeros((num_agents, num_steps))\n",
    "\n",
    "requesting_agents_indices = torch.tensor([0, 2])\n",
    "requesting_agents_incomes = torch.tensor([200, 800], dtype=torch.float32)\n",
    "requesting_payment_amount = _income_to_pua(requesting_agents_incomes)\n",
    "\n",
    "print(\"Inputs...\")\n",
    "print(\"agent payments: \", requesting_payment_amount.shape, requesting_payment_amount)\n",
    "print(\"num steps: \", num_steps_shape.shape)\n",
    "print(\"-------------\")\n",
    "\n",
    "batched_pua_payments_func = torch.vmap(get_pua_payments, in_dims=(0, None, None))\n",
    "batched_pua_payments = batched_pua_payments_func(requesting_payment_amount, num_steps_shape, request_date)\n",
    "sparse_batched_pua_payments = batched_pua_payments.to_sparse_coo()\n",
    "\n",
    "chunked_batched_pua = batched_pua_payments.chunk(chunks=num_agents, dim=0)\n",
    "chunked_pua_payments = pua_payments.chunk(chunks=num_agents, dim=0)\n",
    "\n",
    "print(\"batched pua payments: \", batched_pua_payments)\n",
    "print(\"pua payments\", pua_payments)\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "pua_payments[requesting_agents_indices] = batched_pua_payments\n",
    "sparse_pua_payments = pua_payments.to_sparse_coo()    \n",
    "\n",
    "\n",
    "\n",
    "def start_pua(t, agents_employment, agents_enrollment_status, agents_request_step, agents_income, num_steps_shape, INFINITY_TIME):\n",
    "    '''enrollment_status, request_date, delay, start_date, end_date, recurring_amount, first_payment'''\n",
    "    payment_amount = _income_to_pua(agents_income)\n",
    "    eligible_agents = (agents_employment == 0)\n",
    "    ENROLLMENT_VAR = 1\n",
    "\n",
    "    agents_enrollment_status = agents_enrollment_status*(1-eligible_agents) + ENROLLMENT_VAR*(eligible_agents)\n",
    "    agents_request_step = (eligible_agents)*t + (1-eligible_agents)*agents_request_step\n",
    "\n",
    "    batched_pua_payments_func = torch.vmap(get_eligible_pua_payments, in_dims=(0, None, None))\n",
    "    batched_pua_payments = batched_pua_payments_func(payment_amount, num_steps_shape, agents_request_step)\n",
    "\n",
    "    sparse_batched_pua_payments = batched_pua_payments.to_sparse_coo()\n",
    "    print(batched_pua_payments.shape, sparse_batched_pua_payments)\n",
    "\n",
    "num_agents = 2\n",
    "INFINITY_TIME = 1000\n",
    "agents_income = torch.tensor([200, 800], dtype=torch.float32)\n",
    "agents_employment = torch.tensor([1, 0])\n",
    "num_steps_shape = torch.ones((100))\n",
    "agents_enrollment_status = torch.zeros_like(agents_income)\n",
    "agents_request_step = torch.ones_like(agents_income)*(INFINITY_TIME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## debug vmap indexing from a mask\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "torch.select(x, 0, 1)\n",
    "\n",
    "# explore: torch.chunk\n",
    "x2 = x.chunk(chunks=2, dim=0)\n",
    "len(x2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key bottleneck: handling masks with differentiability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 5])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing at scale with vmap and sparse_tensors\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3, 5, 4, 3, 1])\n",
    "indices = torch.tensor([0, 1, 3])\n",
    "\n",
    "def get_at_indices(tensor, indices):\n",
    "    return tensor[indices]\n",
    "\n",
    "get_at_indices(tensor, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_birds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
