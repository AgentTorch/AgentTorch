{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "import sys\n",
    "sys.path.append('/Users/shashankkumar/Documents/GitHub/MacroEcon/AgentTorch')\n",
    "from AgentTorch.LLM.llm_qa import DocumentRetriever\n",
    "import dspy\n",
    "from typing import List, Union, Optional\n",
    "from dsp.utils import deduplicate\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "directory = \"/Users/shashankkumar/Documents/GitHub/MacroEcon/simulator_data/census_populations/NYC/simulation_memory_output\"\n",
    "search_kwargs = {\"k\": 5}\n",
    "# document_retriever = DocumentRetriever(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs,directory=directory, search_kwargs=search_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain Query Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_runner = QueryRunner(retriever=document_retriever.retriever,openai_api_key=OPENAI_API_KEY)\n",
    "query_runner(query=\"What is the approximate consumption rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dspy Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AgentTorch.LLM.llm_qa import DSPythonicRMClient, QueryRunnerUsingDspy\n",
    "\n",
    "rm = DSPythonicRMClient(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs,directory=directory,search_kwargs=search_kwargs)\n",
    "turbo = dspy.OpenAI(model='gpt-3.5-turbo', api_key=OPENAI_API_KEY)\n",
    "dspy.settings.configure(lm=turbo, rm=rm)\n",
    "# Ask any question you like to this simple RAG program.\n",
    "my_question = \"How many age groups are there in the population?\"\n",
    "\n",
    "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
    "query_runner = QueryRunnerUsingDspy()  # uncompiled (i.e., zero-shot) program\n",
    "pred = query_runner(my_question)\n",
    "\n",
    "# Print the contexts and the answer.\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = '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'\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "directory = \"/Users/shashankkumar/Documents/GitHub/MacroEcon/simulator_data/census_populations/NYC/simulation_memory_output\"\n",
    "search_kwargs = {\"k\": 5}\n",
    "document_retriever = DocumentRetriever(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs,directory=directory, search_kwargs=search_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "\n",
    "# Initialize the OpenAI chat model\n",
    "openai_chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-4\")\n",
    "\n",
    "system_prompt = \"\"\"You are a data analyst responsible for breaking down complex queries into smaller, more manageable subqueries. Your task is to take a given query and split it into a series of subqueries, each building upon the previous one(s), except for the last subquery, which should use the results from the previous subqueries to generate the final answer.\n",
    "\n",
    "For each subquery, provide a clear and concise description of the data or information needed, without including any code. These descriptions will be used by other agents to generate the appropriate Pandas code for retrieving the required data.\n",
    "\n",
    "Your output should be a JSON object with keys representing each subquery, and the corresponding values being the descriptions for those subqueries. The number of subqueries can vary depending on the complexity of the original query, so you should dynamically create the appropriate number of keys in the JSON object.\n",
    "\n",
    "For example, if you have three subqueries, your JSON output should look like this:\n",
    "\n",
    "{{\n",
    "  \"subquery1\": \"Description for subquery 1\",\n",
    "  \"subquery2\": \"Description for subquery 2\",\n",
    "  \"subquery3\": \"Description for subquery 3\"\n",
    "}}\n",
    "\n",
    "Remember, your goal is to provide clear and concise descriptions for each subquery, without including any code. The generated JSON object will be used by other agents to retrieve the necessary data and ultimately generate the final answer to the original query.\"\"\"\n",
    "# Define the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Create a processing chain with the prompt template and the OpenAI chat model\n",
    "processing_chain = prompt_template | openai_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = processing_chain.invoke({\"input\": \"What is the approximate consumption rate for old aged people in the population?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_chain.invoke({\"input\": \"What is the consumption trend for females?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load state variables and Initialise Pandas Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/shashankkumar/Documents/GitHub/MacroEcon/state_data_dict.pkl', 'rb') as handle:\n",
    "    sim_data_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1])\n",
      "dict_keys([0, 1])\n"
     ]
    }
   ],
   "source": [
    "agent_prop_df_list = []\n",
    "for episode in sim_data_dict.keys():\n",
    "    print(sim_data_dict[episode]['agents'].keys())\n",
    "    agent_prop_dict = sim_data_dict[episode]['agents']\n",
    "    for step, agent_prop in agent_prop_dict.items():\n",
    "        processed_data = {'consumers':{}}\n",
    "        for key, value in agent_prop['consumers'].items():\n",
    "            value = value.flatten().squeeze()\n",
    "            processed_data['consumers'][key] = value.numpy()\n",
    "        processed_data['consumers']['assets'] = processed_data['consumers']['assets'][:541516]\n",
    "        df = pd.DataFrame(processed_data['consumers'])\n",
    "        # Flatten the nested structure\n",
    "        df = df.explode(['assets', 'consumption_propensity', 'monthly_consumption', 'monthly_income', 'post_tax_income', 'will_work', 'work_propensity'])\n",
    "        # Ensure consistent data types\n",
    "        df = df.astype({'ID': int, 'age': float, 'area': float, 'assets': float, 'consumption_propensity': float, 'ethnicity': float, 'gender': float, 'monthly_consumption': float, 'monthly_income': float, 'post_tax_income': float, 'will_work': float, 'work_propensity': float,'household_id': int})\n",
    "        df = df.drop('work_propensity', axis=1)\n",
    "        df= df.drop('monthly_consumption', axis=1)\n",
    "        df['month'] = step\n",
    "        df['year'] = episode\n",
    "        agent_prop_df_list.append(df)\n",
    "        # print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            ID  age  area  county  household_id  assets  \\\n",
       " 0            0  0.0   0.0     0.0             0     0.0   \n",
       " 1            1  0.0   0.0     0.0             1     0.0   \n",
       " 2            2  0.0   0.0     0.0             2     0.0   \n",
       " 3            3  0.0   0.0     0.0             3     0.0   \n",
       " 4            4  0.0   0.0     0.0             4     0.0   \n",
       " ...        ...  ...   ...     ...           ...     ...   \n",
       " 541511  541511  5.0  10.0     4.0          9717     0.0   \n",
       " 541512  541512  5.0  10.0     4.0         12690     0.0   \n",
       " 541513  541513  5.0  10.0     4.0         10838     0.0   \n",
       " 541514  541514  5.0  10.0     4.0         18473     0.0   \n",
       " 541515  541515  5.0  10.0     4.0          1122     0.0   \n",
       " \n",
       "         consumption_propensity  ethnicity  gender  monthly_income  \\\n",
       " 0                          0.0        0.0     0.0             0.0   \n",
       " 1                          0.0        1.0     1.0             0.0   \n",
       " 2                          0.0        0.0     1.0             0.0   \n",
       " 3                          0.0        0.0     1.0             0.0   \n",
       " 4                          0.0        0.0     1.0             0.0   \n",
       " ...                        ...        ...     ...             ...   \n",
       " 541511                     0.0        2.0     0.0             0.0   \n",
       " 541512                     0.0        0.0     0.0             0.0   \n",
       " 541513                     0.0        0.0     0.0             0.0   \n",
       " 541514                     0.0        3.0     0.0             0.0   \n",
       " 541515                     0.0        0.0     1.0             0.0   \n",
       " \n",
       "         post_tax_income  will_work  month  year  \n",
       " 0                   0.0        0.0      0     0  \n",
       " 1                   0.0        0.0      0     0  \n",
       " 2                   0.0        0.0      0     0  \n",
       " 3                   0.0        0.0      0     0  \n",
       " 4                   0.0        0.0      0     0  \n",
       " ...                 ...        ...    ...   ...  \n",
       " 541511              0.0        0.0      0     0  \n",
       " 541512              0.0        0.0      0     0  \n",
       " 541513              0.0        0.0      0     0  \n",
       " 541514              0.0        0.0      0     0  \n",
       " 541515              0.0        0.0      0     0  \n",
       " \n",
       " [541516 rows x 14 columns],\n",
       "             ID  age  area  county  household_id    assets  \\\n",
       " 0            0  0.0   0.0     0.0             0  7.902037   \n",
       " 1            1  0.0   0.0     0.0             1  7.902037   \n",
       " 2            2  0.0   0.0     0.0             2  7.902037   \n",
       " 3            3  0.0   0.0     0.0             3  7.902037   \n",
       " 4            4  0.0   0.0     0.0             4  7.902037   \n",
       " ...        ...  ...   ...     ...           ...       ...   \n",
       " 541511  541511  5.0  10.0     4.0          9717  7.902037   \n",
       " 541512  541512  5.0  10.0     4.0         12690  7.902037   \n",
       " 541513  541513  5.0  10.0     4.0         10838  7.902037   \n",
       " 541514  541514  5.0  10.0     4.0         18473  7.902037   \n",
       " 541515  541515  5.0  10.0     4.0          1122  7.902037   \n",
       " \n",
       "         consumption_propensity  ethnicity  gender  monthly_income  \\\n",
       " 0                          0.6        0.0     0.0           168.0   \n",
       " 1                          0.6        1.0     1.0           168.0   \n",
       " 2                          0.6        0.0     1.0           168.0   \n",
       " 3                          0.6        0.0     1.0           168.0   \n",
       " 4                          0.6        0.0     1.0           168.0   \n",
       " ...                        ...        ...     ...             ...   \n",
       " 541511                     0.6        2.0     0.0           168.0   \n",
       " 541512                     0.6        0.0     0.0           168.0   \n",
       " 541513                     0.6        0.0     0.0           168.0   \n",
       " 541514                     0.6        3.0     0.0           168.0   \n",
       " 541515                     0.6        0.0     1.0           168.0   \n",
       " \n",
       "         post_tax_income  will_work  month  year  \n",
       " 0                   0.0        1.0      1     0  \n",
       " 1                   0.0        1.0      1     0  \n",
       " 2                   0.0        1.0      1     0  \n",
       " 3                   0.0        1.0      1     0  \n",
       " 4                   0.0        0.0      1     0  \n",
       " ...                 ...        ...    ...   ...  \n",
       " 541511              0.0        1.0      1     0  \n",
       " 541512              0.0        1.0      1     0  \n",
       " 541513              0.0        1.0      1     0  \n",
       " 541514              0.0        1.0      1     0  \n",
       " 541515              0.0        1.0      1     0  \n",
       " \n",
       " [541516 rows x 14 columns],\n",
       "             ID  age  area  county  household_id  assets  \\\n",
       " 0            0  0.0   0.0     0.0             0     0.0   \n",
       " 1            1  0.0   0.0     0.0             1     0.0   \n",
       " 2            2  0.0   0.0     0.0             2     0.0   \n",
       " 3            3  0.0   0.0     0.0             3     0.0   \n",
       " 4            4  0.0   0.0     0.0             4     0.0   \n",
       " ...        ...  ...   ...     ...           ...     ...   \n",
       " 541511  541511  5.0  10.0     4.0          9717     0.0   \n",
       " 541512  541512  5.0  10.0     4.0         12690     0.0   \n",
       " 541513  541513  5.0  10.0     4.0         10838     0.0   \n",
       " 541514  541514  5.0  10.0     4.0         18473     0.0   \n",
       " 541515  541515  5.0  10.0     4.0          1122     0.0   \n",
       " \n",
       "         consumption_propensity  ethnicity  gender  monthly_income  \\\n",
       " 0                          0.0        0.0     0.0             0.0   \n",
       " 1                          0.0        1.0     1.0             0.0   \n",
       " 2                          0.0        0.0     1.0             0.0   \n",
       " 3                          0.0        0.0     1.0             0.0   \n",
       " 4                          0.0        0.0     1.0             0.0   \n",
       " ...                        ...        ...     ...             ...   \n",
       " 541511                     0.0        2.0     0.0             0.0   \n",
       " 541512                     0.0        0.0     0.0             0.0   \n",
       " 541513                     0.0        0.0     0.0             0.0   \n",
       " 541514                     0.0        3.0     0.0             0.0   \n",
       " 541515                     0.0        0.0     1.0             0.0   \n",
       " \n",
       "         post_tax_income  will_work  month  year  \n",
       " 0                   0.0        0.0      0     1  \n",
       " 1                   0.0        0.0      0     1  \n",
       " 2                   0.0        0.0      0     1  \n",
       " 3                   0.0        0.0      0     1  \n",
       " 4                   0.0        0.0      0     1  \n",
       " ...                 ...        ...    ...   ...  \n",
       " 541511              0.0        0.0      0     1  \n",
       " 541512              0.0        0.0      0     1  \n",
       " 541513              0.0        0.0      0     1  \n",
       " 541514              0.0        0.0      0     1  \n",
       " 541515              0.0        0.0      0     1  \n",
       " \n",
       " [541516 rows x 14 columns],\n",
       "             ID  age  area  county  household_id      assets  \\\n",
       " 0            0  0.0   0.0     0.0             0  164.636353   \n",
       " 1            1  0.0   0.0     0.0             1  164.636353   \n",
       " 2            2  0.0   0.0     0.0             2  164.636353   \n",
       " 3            3  0.0   0.0     0.0             3  164.636353   \n",
       " 4            4  0.0   0.0     0.0             4  164.636353   \n",
       " ...        ...  ...   ...     ...           ...         ...   \n",
       " 541511  541511  5.0  10.0     4.0          9717  164.636353   \n",
       " 541512  541512  5.0  10.0     4.0         12690  164.636353   \n",
       " 541513  541513  5.0  10.0     4.0         10838  164.636353   \n",
       " 541514  541514  5.0  10.0     4.0         18473  164.636353   \n",
       " 541515  541515  5.0  10.0     4.0          1122  164.636353   \n",
       " \n",
       "         consumption_propensity  ethnicity  gender  monthly_income  \\\n",
       " 0                          0.6        0.0     0.0           168.0   \n",
       " 1                          0.6        1.0     1.0           168.0   \n",
       " 2                          0.6        0.0     1.0           168.0   \n",
       " 3                          0.6        0.0     1.0           168.0   \n",
       " 4                          0.6        0.0     1.0           168.0   \n",
       " ...                        ...        ...     ...             ...   \n",
       " 541511                     0.6        2.0     0.0           168.0   \n",
       " 541512                     0.6        0.0     0.0           168.0   \n",
       " 541513                     0.6        0.0     0.0           168.0   \n",
       " 541514                     0.6        3.0     0.0           168.0   \n",
       " 541515                     0.6        0.0     1.0           168.0   \n",
       " \n",
       "         post_tax_income  will_work  month  year  \n",
       " 0                   0.0        1.0      1     1  \n",
       " 1                   0.0        1.0      1     1  \n",
       " 2                   0.0        1.0      1     1  \n",
       " 3                   0.0        1.0      1     1  \n",
       " 4                   0.0        1.0      1     1  \n",
       " ...                 ...        ...    ...   ...  \n",
       " 541511              0.0        1.0      1     1  \n",
       " 541512              0.0        1.0      1     1  \n",
       " 541513              0.0        1.0      1     1  \n",
       " 541514              0.0        1.0      1     1  \n",
       " 541515              0.0        1.0      1     1  \n",
       " \n",
       " [541516 rows x 14 columns]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_prop_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/shashankkumar/Documents/GitHub/MacroEcon/state_data_dict.pkl', 'rb') as handle:\n",
    "    sim_data_dict = pickle.load(handle)\n",
    "agent_prop = sim_data_dict['agents']\n",
    "env_prop = sim_data_dict['environment']\n",
    "\n",
    "processed_data = {'consumers':{}}\n",
    "for key, value in agent_prop['consumers'].items():\n",
    "    value = value.flatten().squeeze()\n",
    "    processed_data['consumers'][key] = value.numpy()\n",
    "processed_data['consumers']['assets'] = processed_data['consumers']['assets'][:541516]\n",
    "df = pd.DataFrame(processed_data['consumers'])\n",
    "# Flatten the nested structure\n",
    "df = df.explode(['assets', 'consumption_propensity', 'monthly_consumption', 'monthly_income', 'post_tax_income', 'will_work', 'work_propensity'])\n",
    "# Ensure consistent data types\n",
    "df = df.astype({'ID': int, 'age': float, 'area': float, 'assets': float, 'consumption_propensity': float, 'ethnicity': float, 'gender': float, 'monthly_consumption': float, 'monthly_income': float, 'post_tax_income': float, 'will_work': float, 'work_propensity': float,'household_id': int})\n",
    "df = df.drop('work_propensity', axis=1)\n",
    "df= df.drop('monthly_consumption', axis=1)\n",
    "\n",
    "openai_llm = OpenAI(\n",
    "    api_token=OPENAI_API_KEY,\n",
    ")\n",
    "mapping  = { \n",
    "    \"age\": [\"20t29\", \"30t39\", \"40t49\", \"50t64\", \"65A\", \"U19\"], \n",
    "    \"gender\": [\"male\", \"female\"], \n",
    "    \"ethnicity\": [\"hispanic\", \"asian\", \"black\", \"white\", \"other\", \"native\"], \n",
    "    \"county\": [\"BK\", \"BX\", \"MN\", \"QN\", \"SI\"]\n",
    "}\n",
    "\n",
    "# Reverse the mapping to map from index to value\n",
    "reverse_mapping = {col: {i: val for i, val in enumerate(vals)} for col, vals in mapping.items()}\n",
    "\n",
    "# Replace the values in the DataFrame\n",
    "df.replace(reverse_mapping, inplace=True)\n",
    "dfs = SmartDataframe(df,config={\"llm\": openai_llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai import Agent\n",
    "\n",
    "pandas_agent = Agent(df,config={\"llm\": openai_llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in out:\n",
    "    print(agent.chat(agent.rephrase_query(out[query])),query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BK</th>\n",
       "      <td>308.772426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BX</th>\n",
       "      <td>306.512096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>305.066703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QN</th>\n",
       "      <td>300.256737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>301.045207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "BK  308.772426\n",
       "BX  306.512096\n",
       "MN  305.066703\n",
       "QN  300.256737\n",
       "SI  301.045207"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_agent.chat(\"What is the income for different counties?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "@tool\n",
    "def run_analysis_on_simulation_state(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Run the analysis on the simulation state\n",
    "    Use this tool to generate Pandas code for data retrieval.\n",
    "    :param query: The query to run\n",
    "    :return: The data analysis result\n",
    "    \"\"\"\n",
    "    return pandas_agent.chat(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_retriever = DocumentRetriever(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs,directory=directory, search_kwargs=search_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# Set your OpenAI API key\n",
    "OPENAI_API_KEY = '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'\n",
    "\n",
    "# Define the system prompt for the OpenAI chat model\n",
    "system_prompt = \"\"\"You are a data analyst responsible for breaking down complex queries into smaller, more manageable subqueries. Your task is to take a given query and split it into a series of subqueries, each building upon the previous one(s), except for the last subquery, which should use the results from the previous subqueries to generate the final answer.\n",
    "\n",
    "For each subquery, provide a clear and concise description of the data or information needed, without including any code. These descriptions will be used by other agents to generate the appropriate Pandas code for retrieving the required data.\n",
    "\n",
    "Your output should be a JSON object with keys representing each subquery, and the corresponding values being the descriptions for those subqueries. The number of subqueries can vary depending on the complexity of the original query, so you should dynamically create the appropriate number of keys in the JSON object.\n",
    "\n",
    "For example, if you have three subqueries, your JSON output should look like this:\n",
    "\n",
    "{\n",
    "\"subquery1\": \"Description for subquery 1\",\n",
    "\"subquery2\": \"Description for subquery 2\",\n",
    "\"subquery3\": \"Description for subquery 3\"\n",
    "}\n",
    "\n",
    "Remember, your goal is to provide clear and concise descriptions for each subquery, without including any code. The generated JSON object will be used by other agents to retrieve the necessary data and ultimately generate the final answer to the original query.\"\"\"\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Initialize the OpenAI chat model\n",
    "openai_chat_model = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-4\", temperature=0)\n",
    "\n",
    "# Initialize the PandasAI tool\n",
    "pandas_agent = Agent(df,config={\"llm\": openai_llm})\n",
    "from langchain.tools import tool\n",
    "@tool\n",
    "def run_analysis_on_simulation_state(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Run the analysis on the simulation state\n",
    "    Use this tool to generate Pandas code for data retrieval.\n",
    "    :param query: The query to run\n",
    "    :return: The data analysis result\n",
    "    \"\"\"\n",
    "    return pandas_agent.chat(query)\n",
    "\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    document_retriever.retriever,\n",
    "    \"simulation_memory_retriever\",\n",
    "    \"You must use this tool to retrive context for each user query!\",\n",
    ")\n",
    "# Initialize the LangChain agent\n",
    "tools = [run_analysis_on_simulation_state, retriever_tool]\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "llm_agent = create_tool_calling_agent(openai_chat_model, tools, prompt)\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=llm_agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `run_analysis_on_simulation_state` with `{'query': 'income by ethnic groups'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m  ethnicity  monthly_income\n",
      "0     asian      302.963905\n",
      "1     black      304.589396\n",
      "2  hispanic      304.865088\n",
      "3    native      303.775176\n",
      "4     other      303.982692\n",
      "5     white      304.542218\u001b[0m\u001b[32;1m\u001b[1;3mThe income distribution among different ethnic groups is relatively even. The monthly income for all groups is around 304 units, with the Asian group having the slightly lowest average income and the Hispanic group having the slightly highest. However, the differences are minimal and may not be statistically significant. This suggests that in this simulation, ethnicity does not appear to be a major factor influencing income levels.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the income for ethnic groups? Give your comment on it.',\n",
       " 'output': 'The income distribution among different ethnic groups is relatively even. The monthly income for all groups is around 304 units, with the Asian group having the slightly lowest average income and the Hispanic group having the slightly highest. However, the differences are minimal and may not be statistically significant. This suggests that in this simulation, ethnicity does not appear to be a major factor influencing income levels.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the income for ethnic groups? Give your comment on it.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `run_analysis_on_simulation_state` with `{'query': 'old age population consumption rate'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1.4270546130343353\u001b[0m\u001b[32;1m\u001b[1;3mThe approximate consumption rate for old aged people in the population is around 1.43. This indicates that the elderly population consumes resources at a higher rate than the average. This could be due to various factors such as increased healthcare needs, reliance on services, or lifestyle choices. It's important to consider these factors when planning resource allocation and services for this demographic.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the approximate consumption rate for old aged people in the population? Give your comment on it.',\n",
       " 'output': \"The approximate consumption rate for old aged people in the population is around 1.43. This indicates that the elderly population consumes resources at a higher rate than the average. This could be due to various factors such as increased healthcare needs, reliance on services, or lifestyle choices. It's important to consider these factors when planning resource allocation and services for this demographic.\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the approximate consumption rate for old aged people in the population? Give your comment on it.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `simulation_memory_retriever` with `{'query': 'white households consumption trend'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee89ffb8237424eb3b71424ff39b870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m0.60,\\n  \"consumption\": 0.80,\\n  \"explanation\": \"As a 65-year-old female living in Brooklyn, with a redistributive tax system in place, my willingness to work this month is at 0.60. I still have the motivation to work and contribute to society, but I also value my leisure time and want to enjoy my\n",
      "\n",
      "0.60,\\n  \"consumption\": 0.80,\\n  \"explanation\": \"As a 65-year-old female living in Staten Island, with a redistributive tax system in place, my willingness to work this month is at 60%. I still have the energy and desire to contribute to society. In terms of consumption, I plan to spend 80% of my\n",
      "\n",
      "0.92,\\n  \"consumption\": 0.75,\\n  \"explanation\": \"Given my age and the current economic situation, I am highly motivated to work this month to secure my financial stability for the future. With the tax system in place, I know that my efforts will contribute to the overall welfare of society. In\n",
      "\n",
      "\"work\": 0.92,\\n  \"consumption\": 0.75,\\n  \"explanation\": \"Given the current economic trends and my age group, I am highly motivated to work this month to secure my financial future. With the tax system in place, I understand the importance of actively contributing to society. As for my consumption,\n",
      "\n",
      "0.80,\\n  \"consumption\": 0.70,\\n  \"explanation\": \"As a 65-year-old male living in Brooklyn, with a redistributive tax system in place, my willingness to work is high at 0.80. Despite being retired, I still have the motivation to engage in part-time work or pursue personal projects. Regarding\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `run_analysis_on_simulation_state` with `{'query': 'white households consumption trend'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m     age  consumption_propensity\n",
      "0  20t29                1.370249\n",
      "1  30t39                1.368450\n",
      "2  40t49                1.429481\n",
      "3  50t64                1.423793\n",
      "4    65A                1.443386\n",
      "5    U19                1.400820\u001b[0m\u001b[32;1m\u001b[1;3mThe consumption trend for white households varies with age. Here are the average consumption propensities for different age groups:\n",
      "\n",
      "- Age 20-29: 1.37\n",
      "- Age 30-39: 1.37\n",
      "- Age 40-49: 1.43\n",
      "- Age 50-64: 1.42\n",
      "- Age 65 and above: 1.44\n",
      "- Under 19: 1.40\n",
      "\n",
      "This suggests that consumption propensity tends to increase with age, with the highest consumption seen in the 65 and above age group.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the consumption trend for white households?',\n",
       " 'output': 'The consumption trend for white households varies with age. Here are the average consumption propensities for different age groups:\\n\\n- Age 20-29: 1.37\\n- Age 30-39: 1.37\\n- Age 40-49: 1.43\\n- Age 50-64: 1.42\\n- Age 65 and above: 1.44\\n- Under 19: 1.40\\n\\nThis suggests that consumption propensity tends to increase with age, with the highest consumption seen in the 65 and above age group.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the consumption trend for white households?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `simulation_memory_retriever` with `{'query': 'extra monthly income of 500 usd'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ce6ae5bb444b14a0d07ce429733a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33;1m\u001b[1;3m(Your explanation for your decision).\"), AIMessage(content='{\\n  \"work\": 0.85,\\n  \"consumption\": 0.60,\\n  \"explanation\": \"This month, I am willing to work at a level of 0.85. The progressive tax system and the knowledge that my income will be redistributed back to all citizens, including myself,\n",
      "\n",
      "0.92,\\n  \"consumption\": 0.75,\\n  \"explanation\": \"Given the progressive tax system and the fact that the government redistributes tax revenue evenly, I am motivated to work hard this month to increase my income. With a high willingness to work, I aim to maximize my earnings. However, I also\n",
      "\n",
      "0.80,\\n  \"consumption\": 0.70,\\n  \"explanation\": \"Given the tax system and redistribution policy in place, I am motivated to work at a high willingness level of 0.80 this month. Knowing that my income will be taxed and then redistributed evenly, I feel encouraged to earn more. As for my consumption,\n",
      "\n",
      "\"work\": 0.92,\\n  \"consumption\": 0.75,\\n  \"explanation\": \"Given the current economic trends and my aspirations for the future, I am highly motivated to work this month. The redistributive tax system ensures that even though a portion of my income is taxed, it will be redistributed back to all\n",
      "\n",
      "\"work\": 0.85,\\n  \"consumption\": 0.60,\\n  \"explanation\": \"This month, I am highly motivated to work with a willingness level of 0.85. The tax system and redistribution policy provide me with a sense of security that my efforts will contribute to the overall welfare of society. In terms of my\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `run_analysis_on_simulation_state` with `{'query': 'extra monthly income of 500 usd'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/shashankkumar/anaconda3/envs/LIDA/lib/python3.10/site-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 283, in run\n",
      "    output = (self.code_generation_pipeline | self.code_execution_pipeline).run(\n",
      "  File \"/Users/shashankkumar/anaconda3/envs/LIDA/lib/python3.10/site-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
      "    raise e\n",
      "  File \"/Users/shashankkumar/anaconda3/envs/LIDA/lib/python3.10/site-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
      "    step_output = logic.execute(\n",
      "  File \"/Users/shashankkumar/anaconda3/envs/LIDA/lib/python3.10/site-packages/pandasai/pipelines/chat/code_execution.py\", line 114, in execute\n",
      "    raise e\n",
      "  File \"/Users/shashankkumar/anaconda3/envs/LIDA/lib/python3.10/site-packages/pandasai/pipelines/chat/code_execution.py\", line 85, in execute\n",
      "    result = self.execute_code(input, code_context)\n",
      "  File \"/Users/shashankkumar/anaconda3/envs/LIDA/lib/python3.10/site-packages/pandasai/pipelines/chat/code_execution.py\", line 176, in execute_code\n",
      "    raise NoResultFoundError(\"No result returned\")\n",
      "pandasai.exceptions.NoResultFoundError: No result returned\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mUnfortunately, I was not able to answer your question, because of the following error:\n",
      "\n",
      "No result returned\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mI'm sorry, but I couldn't find any simulation data related to the scenario where the government provides an extra monthly income of 500 USD. Therefore, I can't provide a precise analysis of how consumption would have changed under these conditions. However, generally speaking, an increase in income often leads to an increase in consumption as people have more disposable income to spend.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How would have consumtpion changed if governement had provided extra monthly income of 500 usd?',\n",
       " 'output': \"I'm sorry, but I couldn't find any simulation data related to the scenario where the government provides an extra monthly income of 500 USD. Therefore, I can't provide a precise analysis of how consumption would have changed under these conditions. However, generally speaking, an increase in income often leads to an increase in consumption as people have more disposable income to spend.\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"How would have consumtpion changed if governement had provided extra monthly income of 500 usd?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subqueries(query):\n",
    "    # Get the response from the OpenAI chat model\n",
    "    response = openai_chat_model(prompt_template.format_prompt(input=query).to_messages())\n",
    "\n",
    "    # Parse the response as JSON\n",
    "    try:\n",
    "        subqueries = json.loads(response.content)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Invalid JSON response. Please try again.\")\n",
    "        return None\n",
    "\n",
    "    return subqueries\n",
    "\n",
    "def process_subqueries(subqueries, data):\n",
    "    results = []\n",
    "    for key, value in subqueries.items():\n",
    "        # Generate Pandas code using PandasAI\n",
    "        pandas_code = llm_agent.run(f\"Generate Pandas code to {value} from the given data.\")\n",
    "        print(f\"Pandas code for {key}: {pandas_code}\")\n",
    "\n",
    "        # Execute the Pandas code and store the result\n",
    "        result = eval(pandas_code)\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the average age of employees in the sales department who have been with the company for more than 5 years?\"\n",
    "\n",
    "# Load sample data\n",
    "data = pd.read_csv(\"employees.csv\")\n",
    "\n",
    "# Generate subqueries\n",
    "subqueries = generate_subqueries(query)\n",
    "\n",
    "if subqueries:\n",
    "    # Process subqueries and generate Pandas code for data retrieval\n",
    "    results = process_subqueries(subqueries, data)\n",
    "\n",
    "    # Code to combine the results from subqueries and generate the final answer goes here\n",
    "    # ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LIDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
